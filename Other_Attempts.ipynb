{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install opencv-python\n",
    "import cv2\n",
    "\n",
    "def take_photo(filename='photo.jpg'):\n",
    "    # Start webcam\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Cannot open webcam\")\n",
    "        return None\n",
    "\n",
    "    print(\"Webcam is running. Press 's' to save photo or 'q' to quit.\")\n",
    "\n",
    "    while True:\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to capture frame\")\n",
    "            break\n",
    "\n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('Live Feed - Press s to Save or q to Quit', frame)\n",
    "\n",
    "        key = cv2.waitKey(1)\n",
    "\n",
    "        if key == ord('s'):  # Press 's' to save photo\n",
    "            cv2.imwrite(filename, frame)\n",
    "            print(f\"Photo saved as {filename}\")\n",
    "            cv2.destroyAllWindows()  # Close the camera window\n",
    "            break\n",
    "        elif key == ord('q'):  # Press 'q' to quit without saving\n",
    "            print(\"Quit without saving\")\n",
    "            cv2.destroyAllWindows()  # Close the camera window\n",
    "            break\n",
    "\n",
    "    # When everything is done, release the capture\n",
    "    cap.release()\n",
    "    return filename\n",
    "\n",
    "\n",
    "# Run the capture function\n",
    "try:\n",
    "    filename = take_photo()\n",
    "    if filename and os.path.exists(filename):\n",
    "        print(f\"Saved to {filename}\")\n",
    "        import os\n",
    "        os.system(f\"open {filename}\")  # Mac image viewer\n",
    "    else:\n",
    "        print(\"No photo was saved.\")\n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes two images and compares the faces, if the images have the same faces then it \n",
    "# returns that it is a match, if its different faces then it returns that it is not a match\n",
    "\n",
    "%pip install opencv-python\n",
    "import cv2\n",
    "\n",
    "def compare_faces(image1_path, image2_path):\n",
    "    # Load the images\n",
    "    image1 = cv2.imread(image1_path)\n",
    "    image2 = cv2.imread(image2_path)\n",
    "\n",
    "    # Convert the images to grayscale\n",
    "    gray1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
    "    gray2 = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Initialize the face detector\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "    # Detect faces in the first image\n",
    "    faces1 = face_cascade.detectMultiScale(gray1, scaleFactor=1.1, minNeighbors=5)\n",
    "    faces2 = face_cascade.detectMultiScale(gray2, scaleFactor=1.1, minNeighbors=5)\n",
    "\n",
    "    if len(faces1) == 0 or len(faces2) == 0:\n",
    "        print(\"No faces found in one or both images.\")\n",
    "        return False\n",
    "\n",
    "    # Compare the first detected face in each image\n",
    "    (x1, y1, w1, h1) = faces1[0]\n",
    "    (x2, y2, w2, h2) = faces2[0]\n",
    "\n",
    "    face1 = gray1[y1:y1+h1, x1:x1+w1]\n",
    "    face2 = gray2[y2:y2+h2, x2:x2+w2]\n",
    "\n",
    "    # Resize the faces to the same size for comparison\n",
    "    face1_resized = cv2.resize(face1, (w1, h1))\n",
    "    face2_resized = cv2.resize(face2, (w1, h1))\n",
    "\n",
    "    # Calculate the difference between the two faces\n",
    "    difference = cv2.absdiff(face1_resized, face2_resized)\n",
    "    \n",
    "    # Convert to grayscale and threshold\n",
    "    _, thresh = cv2.threshold(difference, 30, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Count non-zero pixels in the thresholded image\n",
    "    non_zero_count = cv2.countNonZero(thresh)\n",
    "\n",
    "    # If the number of different pixels is small enough, consider it a match\n",
    "    if non_zero_count < 1000:  # Adjust this threshold as needed\n",
    "        print(\"The faces match!\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"The faces do not match.\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "\n",
    "def compare_faces(img1_path, img2_path):\n",
    "    # Load the images\n",
    "    image1 = face_recognition.load_image_file(img1_path)\n",
    "    image2 = face_recognition.load_image_file(img2_path)\n",
    "\n",
    "    # Get face encodings\n",
    "    encoding1 = face_recognition.face_encodings(image1)\n",
    "    encoding2 = face_recognition.face_encodings(image2)\n",
    "\n",
    "    if not encoding1:\n",
    "        print(f\"No face found in {img1_path}\")\n",
    "        return\n",
    "    if not encoding2:\n",
    "        print(f\"No face found in {img2_path}\")\n",
    "        return\n",
    "\n",
    "    # Compare faces\n",
    "    match = face_recognition.compare_faces([encoding1[0]], encoding2[0], tolerance=0.6)\n",
    "\n",
    "    if match[0]:\n",
    "        print(\"Match: Same person\")\n",
    "    else:\n",
    "        print(\"No match: Different people\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_faces(\"known_faces/person1.png\", \"known_faces/test.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "img1 = Image.open(\"known_faces/person1.jpg\")\n",
    "img2 = Image.open(\"known_faces/test.jpg\")\n",
    "\n",
    "print(\"Known Image:\")\n",
    "display(img1)\n",
    "\n",
    "print(\"Test Image:\")\n",
    "display(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install requests\n",
    "%pip install requests pillow face-recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import face_recognition\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def preprocess_image(image):\n",
    "    # Check and print if the image is in RGB mode\n",
    "    print(f\"Preprocessing image. Current mode: {image.mode}\")\n",
    "    if image.mode != 'RGB':\n",
    "        print(\"Image is not in RGB mode. Converting to RGB...\")\n",
    "        image = image.convert('RGB')\n",
    "    else:\n",
    "        print(\"Image is already in RGB mode.\")\n",
    "\n",
    "    # Check for alpha channel and remove it\n",
    "    if image.mode == 'RGBA':\n",
    "        print(\"Image has an alpha channel. Removing alpha channel...\")\n",
    "        image = image.convert('RGB')\n",
    "\n",
    "    # Convert to NumPy array\n",
    "    img_array = np.array(image, dtype=np.uint8)\n",
    "\n",
    "    # Ensure C-contiguous memory layout\n",
    "    img_array = np.ascontiguousarray(img_array)\n",
    "\n",
    "    # Debug: Print image properties\n",
    "    print(f\"Processed image properties:\")\n",
    "    print(f\"- Shape: {img_array.shape}\")\n",
    "    print(f\"- Dtype: {img_array.dtype}\")\n",
    "    print(f\"- Min value: {img_array.min()}, Max value: {img_array.max()}\")\n",
    "    print(f\"- C_CONTIGUOUS: {img_array.flags['C_CONTIGUOUS']}\")\n",
    "\n",
    "    # Save the processed image for inspection\n",
    "    Image.fromarray(img_array).save(\"processed_image.jpg\")\n",
    "    print(\"Processed image saved as 'processed_image.jpg'.\")\n",
    "\n",
    "    return img_array\n",
    "\n",
    "def compare_faces_from_urls(url1, url2):\n",
    "    try:\n",
    "        def load_image_from_url(url):\n",
    "            response = requests.get(url, timeout=10)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            # Open with PIL\n",
    "            img = Image.open(BytesIO(response.content))\n",
    "\n",
    "            # Preprocess the image\n",
    "            return preprocess_image(img)\n",
    "\n",
    "        # Load and preprocess both images\n",
    "        image1 = load_image_from_url(url1)\n",
    "        image2 = load_image_from_url(url2)\n",
    "\n",
    "        # Encode the faces\n",
    "        encodings1 = face_recognition.face_encodings(image1)\n",
    "        encodings2 = face_recognition.face_encodings(image2)\n",
    "\n",
    "        # Check if any faces were detected\n",
    "        if len(encodings1) == 0 or len(encodings2) == 0:\n",
    "            print(\"No faces detected in one or both images.\")\n",
    "            return False\n",
    "\n",
    "        # Compare the first face in each image\n",
    "        match = face_recognition.compare_faces([encodings1[0]], encodings2[0])\n",
    "\n",
    "        if match[0]:\n",
    "            print(\"The faces match!\")\n",
    "            return True\n",
    "        else:\n",
    "            print(\"The faces do not match.\")\n",
    "            return False\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_faces_from_urls(\n",
    "    \"https://ooiszpalwebsurwuuvjn.supabase.co/storage/v1/object/public/patient-images/patient-images/daaf74d2-d950-41b0-9445-05141b4e5818.jpg\",\n",
    "    \"https://ooiszpalwebsurwuuvjn.supabase.co/storage/v1/object/public/patient-images/patient-images/daaf74d2-d950-41b0-9445-05141b4e5818.jpg\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def take_photo(filename='photo.jpg'):\n",
    "    # Start webcam\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Cannot open webcam\")\n",
    "        return None\n",
    "\n",
    "    print(\"Webcam is running. Press 's' to save photo or 'q' to quit.\")\n",
    "\n",
    "    while True:\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to capture frame\")\n",
    "            break\n",
    "\n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('Live Feed - Press s to Save or q to Quit', frame)\n",
    "\n",
    "        key = cv2.waitKey(1)\n",
    "\n",
    "        if key == ord('s'):  # Press 's' to save photo\n",
    "            cv2.imwrite(filename, frame)\n",
    "            print(f\"Photo saved as {filename}\")\n",
    "            cv2.destroyAllWindows()  # Close the camera window\n",
    "            break\n",
    "        elif key == ord('q'):  # Press 'q' to quit without saving\n",
    "            print(\"Quit without saving\")\n",
    "            cv2.destroyAllWindows()  # Close the camera window\n",
    "            break\n",
    "\n",
    "    # When everything is done, release the capture\n",
    "    cap.release()\n",
    "    return filename\n",
    "\n",
    "\n",
    "# Run the capture function\n",
    "try:\n",
    "    filename = take_photo()\n",
    "    if filename and os.path.exists(filename):\n",
    "        print(f\"Saved to {filename}\")\n",
    "        import os\n",
    "        os.system(f\"open {filename}\")  # Mac image viewer\n",
    "    else:\n",
    "        print(\"No photo was saved.\")\n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepface import DeepFace\n",
    "\n",
    "def compare_faces_from_urls(url1, url2):\n",
    "    try:\n",
    "        print(\"Comparing faces...\")\n",
    "        \n",
    "        result = DeepFace.verify(\n",
    "            img1_path=url1,\n",
    "            img2_path=url2,\n",
    "            model_name='Facenet',           \n",
    "            detector_backend='opencv',      \n",
    "            enforce_detection=True\n",
    "        )\n",
    "\n",
    "        if result[\"verified\"]:\n",
    "            print(\"Match: The faces belong to the same person.\")\n",
    "            return True\n",
    "        else:\n",
    "            print(\"No Match: The faces belong to different people.\")\n",
    "            return False\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during face comparison: {e}\")\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_faces_from_urls(\n",
    "    \"https://ooiszpalwebsurwuuvjn.supabase.co/storage/v1/object/public/patient-images/patient-images/daaf74d2-d950-41b0-9445-05141b4e5818.jpg\",\n",
    "    \"https://static.wikia.nocookie.net/marvelmovies/images/2/2f/Tom_Holland.jpg/revision/latest?cb=20180221210317\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
